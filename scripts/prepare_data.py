import os
import pandas as pd

# ğŸ”§ Chemins absolus automatiques
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")

IN_CSV      = os.path.join(DATA_DIR, "historique_hourly.csv")
OUT_PARQUET = os.path.join(DATA_DIR, "historique_hourly.parquet")

print("ğŸ“ Dossier base :", BASE_DIR)
print("ğŸ“ Recherche CSV ici :", IN_CSV)

if not os.path.exists(IN_CSV):
    raise FileNotFoundError(f"âŒ Introuvable : {IN_CSV}. Lance lâ€™agrÃ©gation dâ€™abord.")

# 1) Charger CSV
df = pd.read_csv(IN_CSV, parse_dates=["ts_hour"])
print(f"ğŸ“¥ ChargÃ© : {IN_CSV} | {len(df):,} lignes")

# 2) Quality checks
print("\nğŸ” VÃ©rifications qualitÃ© :")

# nombre de stations uniques
n_stations = df["stationcode"].nunique()
print(f"  â€¢ Stations uniques : {n_stations}")

# coordonnÃ©es valides
invalid_coords = df[(df["lat"].isna()) | (df["lon"].isna())]
print(f"  â€¢ CoordonnÃ©es invalides : {len(invalid_coords)}")

# doublons
dup = df.duplicated(subset=["stationcode", "ts_hour"])
print(f"  â€¢ Doublons trouvÃ©s : {dup.sum()}")

# Si doublons â†’ suppression
if dup.any():
    df = df[~dup]
    print(f"    âœ… Doublons supprimÃ©s â†’ {len(df):,} lignes restantes")

# 3) Sauvegarde en Parquet
os.makedirs(DATA_DIR, exist_ok=True)  # crÃ©e le dossier data sâ€™il manque
df.to_parquet(OUT_PARQUET, index=False)
print(f"\nâœ… Fichier Parquet Ã©crit : {OUT_PARQUET}")